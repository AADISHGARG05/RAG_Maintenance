# ğŸ”§ Maintenance Knowledge RAG Assistant for Technicians

A **production-grade Retrieval-Augmented Generation (RAG) system** deployed on the cloud that enables technicians and engineers to query maintenance manuals and technical documents with **accurate, hallucination-free answers**.

This project demonstrates a **fully deployed end-to-end AI application**, covering document ingestion, vector search, cloud-hosted retrieval, LLM-based generation, backend APIs, and a modern web interface.

---

## ğŸŒ Live Demo

ğŸš€ **Deployed on Render:**  
ğŸ‘‰ https://your-render-app-url.onrender.com  
*(Link will be updated)*

To test the RAG
- You can as questions like - (From my uploaded documents on airline manuals)
â€œHow to replace a hydraulic pump?â€
â€œWhat causes landing gear extension failure?â€
â€œWhat are engine oil servicing steps?â€
---

## ğŸš€ Key Features

- ğŸ“„ PDF ingestion and semantic chunking  
- ğŸ” Vector similarity search using **Qdrant Cloud**  
- ğŸ§  Retrieval-Augmented Generation (RAG) for grounded responses  
- âš¡ Ultra-fast LLM inference using **Groq**  
- ğŸŒ Flask backend with REST API  
- ğŸ–¥ï¸ Professional landing page + interactive chat UI  
- ğŸ” Secure configuration using environment variables  
- â˜ï¸ Fully deployed cloud-native architecture  

---

## ğŸ§  What is RAG?

**Retrieval-Augmented Generation (RAG)** combines:
1. **Information Retrieval** â€“ fetches relevant document chunks from a vector database  
2. **Language Generation** â€“ generates answers strictly grounded in retrieved content  

This ensures:
- âŒ No hallucinations  
- âœ… Traceable, document-backed answers  
- âœ… High reliability for technical and industrial use cases  

---

## ğŸ—ï¸ System Architecture
User (Browser)
â†“
Home Page / Chat UI (HTML, CSS, JS)
â†“
Flask Backend (Render Deployment)
â†“
Retriever (Sentence Transformers)
â†“
Qdrant Cloud (Vector Database)
â†“
Groq LLM (Hosted Inference)
â†“
Grounded Answer + Sources

---

## ğŸ§° Tech Stack

### Backend
- Python
- Flask

### Vector Database
- Qdrant Cloud

### Embeddings
- Sentence Transformers (`all-MiniLM-L6-v2`)

### LLM Inference
- Groq (`llama3-8b-8192`)

### Frontend
- HTML
- CSS
- Vanilla JavaScript

### Deployment
- **Render (Flask App Hosting)**
- Qdrant Cloud
- Groq API

---

## ğŸ“ Project Structure

â”œâ”€â”€ app.py # Flask entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ config/
â”‚ â””â”€â”€ settings.py # Environment-based configuration
â”‚
â”œâ”€â”€ rag/
â”‚ â”œâ”€â”€ ingestion.py # PDF loading
â”‚ â”œâ”€â”€ embeddings.py # Vector embedding & storage
â”‚ â”œâ”€â”€ retriever.py # Similarity search
â”‚ â””â”€â”€ generator.py # Groq LLM generation
â”‚
â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ index.html # Home / landing page
â”‚ â””â”€â”€ chat.html # Chat UI
â”‚
â”œâ”€â”€ static/
â”‚ â”œâ”€â”€ css/
â”‚ â”‚ â”œâ”€â”€ home.css
â”‚ â”‚ â””â”€â”€ chat.css
â”‚ â””â”€â”€ js/
â”‚ â”œâ”€â”€ home.js
â”‚ â””â”€â”€ chat.js
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ *.pdf # Maintenance documents
â”‚
â”œâ”€â”€ create_collection.py # Create Qdrant collection
â”œâ”€â”€ run_ingestion.py # Ingest documents into Qdrant
â””â”€â”€ test_rag.py # RAG pipeline test

